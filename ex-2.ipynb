{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.7 64-bit ('pytorch_deeplearning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "2bcd7ec7ba57b04cf90fee3838748171677195bfc714753350d4adb3113cc5c7"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# %cd /content/drive/MyDrive/Colab Notebooks/Question_Pairs_new/Question_Pairs_BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from tokenizers import BertWordPieceTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from datetime import datetime\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "# !nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val = train_test_split(df, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, docs_1, docs_2, labels, tokenizer_path):\n",
    "        self.docs_1 = docs_1\n",
    "        self.docs_2 = docs_2\n",
    "        self.labels = labels\n",
    "        self.tokenizer = BertWordPieceTokenizer(tokenizer_path)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.docs_1)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        docs_1 = str(self.docs_1[item])\n",
    "        docs_2 = str(self.docs_2[item])\n",
    "        labels = int(self.labels[item])\n",
    "        encoded_docs_1 = self.tokenizer.encode(docs_1)\n",
    "        encoded_docs_2 = self.tokenizer.encode(docs_2)\n",
    "        return dict(\n",
    "            docs_1 = docs_1, \n",
    "            docs_2 = docs_2, \n",
    "            labels = labels,\n",
    "            tokenized_doc_1 = encoded_docs_1.tokens,\n",
    "            tokenized_doc_2 = encoded_docs_2.tokens,\n",
    "            input_ids_1 = torch.tensor(encoded_docs_1.ids),\n",
    "            input_ids_2 = torch.tensor(encoded_docs_2.ids)\n",
    "            ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\n",
    "    data_train.question1.to_numpy(),\n",
    "    data_train.question2.to_numpy(), \n",
    "    data_train.is_duplicate.to_numpy(),\n",
    "    'BPE/vocab.txt'\n",
    "    )\n",
    "validation_data = CustomDataset(\n",
    "    data_val.question1.to_numpy(),\n",
    "    data_val.question2.to_numpy(), \n",
    "    data_val.is_duplicate.to_numpy(),\n",
    "    'BPE/vocab.txt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "def padding(data):\n",
    "    q1 = []\n",
    "    q2 = []\n",
    "    t = []\n",
    "    for i in data:\n",
    "        q1.append(i['input_ids_1'])\n",
    "        q2.append(i['input_ids_2'])\n",
    "        t.append(i['labels'])\n",
    "    q1_pad = pad_sequence(q1, batch_first=True)\n",
    "    q2_pad = pad_sequence(q2, batch_first=True)\n",
    "    # t_pad = pad_sequence(t, batch_first=True)\n",
    "    return q1_pad, q2_pad, torch.tensor(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_data, batch_size = 64, collate_fn=padding)\n",
    "validation_loader = data.DataLoader(validation_data, batch_size = 128, collate_fn=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "questions_1: tensor([[   2, 1394, 1414,  ...,    0,    0,    0],\n        [   2, 1399, 1669,  ...,    0,    0,    0],\n        [   2, 1394, 1399,  ...,    0,    0,    0],\n        ...,\n        [   2, 1406, 1683,  ...,    0,    0,    0],\n        [   2, 1555, 1399,  ...,    0,    0,    0],\n        [   2, 1394, 1399,  ...,    0,    0,    0]]), shape: torch.Size([64, 33])\nquestions_2: tensor([[   2, 1394, 1414,  ...,    0,    0,    0],\n        [   2, 1414, 2575,  ...,    0,    0,    0],\n        [   2, 1394, 1414,  ...,    0,    0,    0],\n        ...,\n        [   2, 1406, 1460,  ...,    0,    0,    0],\n        [   2, 1659, 1388,  ...,    0,    0,    0],\n        [   2, 1394, 1399,  ...,    0,    0,    0]]), shape: torch.Size([64, 35])\nlables: tensor([0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n        0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]), shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for q1, q2, t in train_loader:\n",
    "    print('questions_1: {}, shape: {}'.format(q1, q1.shape))\n",
    "    print('questions_2: {}, shape: {}'.format(q2, q2.shape))\n",
    "    print('lables: {}, shape: {}'.format(t, t.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "questions_1: tensor([[   2, 1406, 1401,  ...,    0,    0,    0],\n        [   2, 1394, 1414,  ...,    0,    0,    0],\n        [   2, 1491, 1399,  ...,    0,    0,    0],\n        ...,\n        [   2, 1394, 1399,  ...,    0,    0,    0],\n        [   2, 1406, 1420,  ...,    0,    0,    0],\n        [   2, 1406, 1420,  ...,    0,    0,    0]]), shape: torch.Size([128, 51])\nquestions_2: tensor([[   2, 1406, 1401,  ...,    0,    0,    0],\n        [   2, 1394, 1414,  ...,    0,    0,    0],\n        [   2, 1394, 1399,  ...,    0,    0,    0],\n        ...,\n        [   2, 1394, 3328,  ...,    0,    0,    0],\n        [   2, 1420, 9800,  ...,    0,    0,    0],\n        [   2, 1406, 1420,  ...,    0,    0,    0]]), shape: torch.Size([128, 62])\nlables: tensor([0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n        1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0,\n        0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n        0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n        0, 1, 0, 0, 0, 1, 0, 0]), shape: torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for q1, q2, t in validation_loader:\n",
    "    print('questions_1: {}, shape: {}'.format(q1, q1.shape))\n",
    "    print('questions_2: {}, shape: {}'.format(q2, q2.shape))\n",
    "    print('lables: {}, shape: {}'.format(t, t.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "q1 itos : ['India', ':', 'What', 'are', 'job', 'options', 'and', 'future', 'options', 'for', 'low', 'C', '##GP', '##A', 'or', 'graduation', 'percentage', 'engineering', 'students', 'in', 'India', '(', '5', '-', '6', ')', '?', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n===================\nq2 itos : ['Job', '##s', 'and', 'Career', '##s', 'in', 'India', ':', 'I', 'am', 'currently', 'in', 'my', 'third', 'year', 'of', 'engineering', 'and', 'I', 'have', 'a', 'C', '##GP', '##A', 'of', '7', '.', '6', 'with', 'one', 'back', '##log', '(', 'after', '4', 'semester', '##s', ')', '.', 'I', 'have', 'decided', 'that', 'I', 'want', 'to', 'seek', 'a', 'job', 'in', 'a', 'firm', 'like', 'Mu', 'Sigma', 'or', 'do', 'MBA', '.', 'Which', 'option', 'is', 'better', 'and']\n===================\nlabel : 0\n"
     ]
    }
   ],
   "source": [
    "# itos\n",
    "batch_train = next(iter(train_loader))\n",
    "print(f\"q1 itos : {tokenizer.convert_ids_to_tokens(batch_train['input_ids_1'][0])}\")\n",
    "print('===================')\n",
    "print(f\"q2 itos : {tokenizer.convert_ids_to_tokens(batch_train['input_ids_2'][0])}\")\n",
    "print('===================')\n",
    "print(f\"label : {batch_train['labels'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tokenizer'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-164-800ea33c4ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vocab_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_deeplearning\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5129\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5132\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "source": [
    "data_train.tokenizer.get_vocab_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    def __init__(self, n_vocabs, embed_dims, n_lstm_units, n_lstm_layers, n_output_classes):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.v = n_vocabs\n",
    "        self.e = embed_dims\n",
    "        self.u = n_lstm_units\n",
    "        self.l = n_lstm_layers\n",
    "        self.o = n_output_classes\n",
    "\n",
    "        self.embed = nn.Embedding(\n",
    "            self.v,\n",
    "            self.e\n",
    "            )\n",
    "        self.bilstm = nn.LSTM(\n",
    "            input_size = self.e,\n",
    "            hidden_size = self.u,\n",
    "            num_layers = self.l,\n",
    "            batch_first = True,\n",
    "            bidirectional = True,\n",
    "            dropout = 0.5\n",
    "        )\n",
    "        self.linear = nn.Linear(\n",
    "            self.u * 4,\n",
    "            self.o\n",
    "        )\n",
    "\n",
    "    def forward(self, X1, X2):\n",
    "        h0 = torch.zeros(self.l * 2, X1.size(0), self.u).to(gpu)\n",
    "        c0 = torch.zeros(self.l * 2, X1.size(0), self.u).to(gpu)\n",
    "        out1 = self.embed(X1)\n",
    "        out2 = self.embed(X2)\n",
    "        # NxTxh, lxNxh\n",
    "        out1, _ = self.bilstm(out1, (h0, c0))\n",
    "        out2, _ = self.bilstm(out2, (h0, c0))\n",
    "        out1 = out1[:, -1, :]\n",
    "        out2 = out2[:, -1, :]\n",
    "        # concatenate out1&2\n",
    "        out = torch.cat((out1, out2), 1)\n",
    "        out = self.linear(out)\n",
    "        iout = torch.max(out, 1)[1]\n",
    "        \n",
    "        return iout, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = BiLSTM(len(vocab), 512, 512, 2, 2).to(gpu)\n",
    "criterion = nn.CrossEntropyLoss().to(gpu)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr = 0.001\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "BiLSTM(\n  (embed): Embedding(65494, 512)\n  (bilstm): LSTM(512, 512, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n  (linear): Linear(in_features=2048, out_features=2, bias=True)\n)\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "epoch: 1/20:\n",
      "------------------------------------------------------------------------------------------\n",
      "training loss: 0.0087, acc: 0.71\n",
      "validation loss: 0.0041, acc: 0.74\n",
      "epoch time: 1631.84 seconds\n",
      "validation loss decreased from inf to 0.0041, saving model...\n",
      "------------------------------------------------------------------------------------------\n",
      "epoch: 2/20:\n",
      "------------------------------------------------------------------------------------------\n",
      "training loss: 0.0072, acc: 0.78\n",
      "validation loss: 0.0040, acc: 0.75\n",
      "epoch time: 1739.33 seconds\n",
      "validation loss decreased from 0.0041 to 0.0040, saving model...\n",
      "------------------------------------------------------------------------------------------\n",
      "epoch: 3/20:\n",
      "------------------------------------------------------------------------------------------\n",
      "training loss: 0.0056, acc: 0.84\n",
      "validation loss: 0.0044, acc: 0.76\n",
      "epoch time: 1735.03 seconds\n",
      "------------------------------------------------------------------------------------------\n",
      "epoch: 4/20:\n",
      "------------------------------------------------------------------------------------------\n",
      "training loss: 0.0041, acc: 0.89\n",
      "validation loss: 0.0049, acc: 0.75\n",
      "epoch time: 1713.75 seconds\n",
      "------------------------------------------------------------------------------------------\n",
      "epoch: 5/20:\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-0c6c37e3918d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_deeplearning\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch_deeplearning\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "num_epochs = 20\n",
    "losses = []\n",
    "accuracies  = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_loss_min = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    print('epoch: {}/{}:'.format(epoch + 1, num_epochs))   \n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    t0 = time.time()\n",
    "\n",
    "    train_tqdm_bar = tqdm(enumerate(train_iter), total = (len(train_iter)), leave = False, position = 0, file = sys.stdout, dynamic_ncols = True)\n",
    "    val_tqdm_bar = tqdm(enumerate(valid_iter), total = (len(valid_iter)),  leave = False, position = 0, file = sys.stdout, dynamic_ncols = True)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for idx, (questions, labels) in train_tqdm_bar:\n",
    "        iout, out = model(questions[0], questions[1])\n",
    "        loss = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        running_corrects += torch.sum(iout == labels)\n",
    "        train_tqdm_bar.set_description(desc = 'train   '.format(epoch + 1, num_epochs))\n",
    "        batch_idx = (idx + 1) * 64\n",
    "\n",
    "        train_tqdm_bar.set_postfix(\n",
    "            loss = running_loss.item() / batch_idx if idx + 1 < len(train_iter) else running_loss.item() / len(train_iter.dataset)\n",
    "            ,acc = running_corrects.item() / batch_idx if idx + 1 < len(train_iter) else running_corrects.item() / len(train_iter.dataset)\n",
    "            )\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_idx, (v_questions, v_labels) in val_tqdm_bar:\n",
    "            v_iout, v_out = model(v_questions[0], v_questions[1])\n",
    "            v_loss = criterion(v_out, v_labels)\n",
    "            val_running_loss += v_loss\n",
    "            val_running_corrects += torch.sum(v_iout == v_labels)\n",
    "            val_tqdm_bar.set_description('validate'.format(epoch + 1, num_epochs))\n",
    "            val_batch_idx = (val_idx + 1) * 128\n",
    "\n",
    "            val_tqdm_bar.set_postfix(\n",
    "            val_loss = val_running_loss.item() / val_batch_idx if val_idx + 1 < len(valid_iter) else val_running_loss.item() / len(valid_iter.dataset)\n",
    "            ,val_acc = val_running_corrects.item() / val_batch_idx if val_idx + 1 < len(valid_iter) else val_running_corrects.item() / len(valid_iter.dataset)\n",
    "            )\n",
    "    \n",
    "    epoch_loss = running_loss/len(train_iter.dataset)\n",
    "    losses.append(epoch_loss)\n",
    "    epoch_accuracy = running_corrects/len(train_iter.dataset)\n",
    "    accuracies.append(epoch_accuracy)\n",
    "    val_epoch_loss = val_running_loss/len(valid_iter.dataset)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_epoch_accuracy = val_running_corrects/len(valid_iter.dataset)\n",
    "    val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1\n",
    "            ,'state_dict': model.state_dict()\n",
    "            ,'optimizer' : optimizer.state_dict()\n",
    "            ,'val_loss_min' : val_epoch_loss\n",
    "        }\n",
    "    \n",
    "    print('training loss: {:.4f}, acc: {:.2f}'.format(epoch_loss, epoch_accuracy))\n",
    "    print('validation loss: {:.4f}, acc: {:.2f}'.format(val_epoch_loss, val_epoch_accuracy))\n",
    "    print('epoch time: {:.2f} seconds'.format(time.time() - t0))\n",
    "\n",
    "    if val_epoch_loss <= val_loss_min:\n",
    "        print('validation loss decreased from {:.4f} to {:.4f}, saving model...'.format(val_loss_min, val_epoch_loss))\n",
    "        torch.save(checkpoint, 'checkpoint/question_pairs_lowest_val_loss_epoch_{}.pth'.format(epoch + 1))\n",
    "        val_loss_min = val_epoch_loss"
   ]
  }
 ]
}