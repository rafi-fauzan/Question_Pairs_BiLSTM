{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 931,
     "status": "ok",
     "timestamp": 1616587045324,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "1DAW5JWzCJ7Y",
    "outputId": "f722454b-8a22-4368-8725-7912246338b4"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Question_Pairs_BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1215,
     "status": "ok",
     "timestamp": 1616587045618,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "BIpa0MkPB5a1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3181,
     "status": "ok",
     "timestamp": 1616587047589,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "V8WSUFOKoUWB"
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('data/train_dataset.csv')\n",
    "data_val = pd.read_csv('data/val_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfk0fsi0B5bF"
   },
   "source": [
    "### Bert WordPiece Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5904,
     "status": "ok",
     "timestamp": 1616587050318,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "zvDD4Mj-do5T"
   },
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5898,
     "status": "ok",
     "timestamp": 1616587050319,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "vdItZCoKB5bF"
   },
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6382,
     "status": "ok",
     "timestamp": 1616587050809,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "O-mYlJC1pDm6"
   },
   "outputs": [],
   "source": [
    "f = open('data/questions.raw', 'w', encoding='utf-8')\n",
    "for i in data_train.question1.to_list() + data_train.question2.to_list() + data_val.question1.to_list() + data_val.question2.to_list():\n",
    "    f.write(i)\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6378,
     "status": "ok",
     "timestamp": 1616587050810,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "WEpYfJMiB5bG"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertWordPieceTokenizer(lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31490,
     "status": "ok",
     "timestamp": 1616587075926,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "6eAo8ZA5B5bH"
   },
   "outputs": [],
   "source": [
    "tokenizer.train('data/questions.raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31484,
     "status": "ok",
     "timestamp": 1616587075929,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "Zlztd8eutTyG",
    "outputId": "48912098-2154-41a4-d59e-715b3037be6e"
   },
   "outputs": [],
   "source": [
    "tokenizer.save_model('data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 31479,
     "status": "ok",
     "timestamp": 1616587075931,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "FbBsSrqxB5bI",
    "outputId": "524f75e0-ed0d-441d-c649-e70a9bf20f66"
   },
   "outputs": [],
   "source": [
    "# test\n",
    "print('tokens: {}'.format(tokenizer.encode(\"I'am Crazy Man!!!\").tokens))\n",
    "print('ids: {}'.format(tokenizer.encode(\"I'am Crazy Man!!!\").ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XwNFBoXMB5bI"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32167,
     "status": "ok",
     "timestamp": 1616587076625,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "G56ibQO-B5bJ"
   },
   "outputs": [],
   "source": [
    "from torch.utils import data\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32163,
     "status": "ok",
     "timestamp": 1616587076626,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "eOgywQGwB5bJ"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, docs_1, docs_2, labels, tokenizer):\n",
    "        self.docs_1 = docs_1\n",
    "        self.docs_2 = docs_2\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.docs_1)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        docs_1 = str(self.docs_1[item])\n",
    "        docs_2 = str(self.docs_2[item])\n",
    "        labels = int(self.labels[item])\n",
    "        encoded_docs_1 = self.tokenizer.encode(docs_1)\n",
    "        encoded_docs_2 = self.tokenizer.encode(docs_2)\n",
    "        return dict(\n",
    "            input_ids_1 = torch.tensor(encoded_docs_1.ids),\n",
    "            input_ids_2 = torch.tensor(encoded_docs_2.ids),\n",
    "            labels = labels\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32159,
     "status": "ok",
     "timestamp": 1616587076626,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "pLA4BxHKB5bK"
   },
   "outputs": [],
   "source": [
    "train_data = CustomDataset(\n",
    "    data_train.question1.to_numpy(),\n",
    "    data_train.question2.to_numpy(), \n",
    "    data_train.is_duplicate.to_numpy(),\n",
    "    tokenizer\n",
    "    )\n",
    "validation_data = CustomDataset(\n",
    "    data_val.question1.to_numpy(),\n",
    "    data_val.question2.to_numpy(), \n",
    "    data_val.is_duplicate.to_numpy(),\n",
    "    tokenizer\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32155,
     "status": "ok",
     "timestamp": 1616587076627,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "IWRWxWyKB5bK"
   },
   "outputs": [],
   "source": [
    "def padding(batch):\n",
    "    q1 = [q1['input_ids_1'] for q1 in batch]\n",
    "    q2 = [q2['input_ids_2'] for q2 in batch]\n",
    "    t = [t['labels'] for t in batch]\n",
    "    len_q1 = [len(q1['input_ids_1']) for q1 in batch]\n",
    "    len_q2 = [len(q2['input_ids_2']) for q2 in batch]\n",
    "    q1_pad = pad_sequence(q1, batch_first=True, padding_value=0)\n",
    "    q2_pad = pad_sequence(q2, batch_first=True, padding_value=0)\n",
    "    return q1_pad, q2_pad, torch.tensor(t), len_q1, len_q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32152,
     "status": "ok",
     "timestamp": 1616587076628,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "-Xcgb1FiB5bL"
   },
   "outputs": [],
   "source": [
    "train_loader = data.DataLoader(train_data, batch_size = 64, shuffle=True, collate_fn=padding)\n",
    "validation_loader = data.DataLoader(validation_data, batch_size = 128, collate_fn=padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32146,
     "status": "ok",
     "timestamp": 1616587076628,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "kQhBp_4mB5bL",
    "outputId": "4225cdad-7412-41a1-fc8f-0d00594bb9d9"
   },
   "outputs": [],
   "source": [
    "for q1_pad, q2_pad, t, len_q1, len_q2 in train_loader:\n",
    "    print('questions_1: {}, shape: {}'.format(q1_pad, q1_pad.shape))\n",
    "    print('')\n",
    "    print('len_questions_1: {}'.format(len_q1))\n",
    "    print('')\n",
    "    print('questions_2: {}, shape: {}'.format(q2_pad, q2_pad.shape))\n",
    "    print('')\n",
    "    print('len_questions_2: {}'.format(len_q2))\n",
    "    print('')\n",
    "    print('lables: {}, shape: {}'.format(t, t.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32140,
     "status": "ok",
     "timestamp": 1616587076629,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "MFGA45-IB5bL",
    "outputId": "93e1e836-d855-4b7f-92d9-7626458776c1"
   },
   "outputs": [],
   "source": [
    "for q1_pad, q2_pad, t, len_q1, len_q2 in validation_loader:\n",
    "    print('questions_1: {}, shape: {}'.format(q1_pad, q1_pad.shape))\n",
    "    print('')\n",
    "    print('len_questions_1: {}'.format(len_q1))\n",
    "    print('')\n",
    "    print('questions_2: {}, shape: {}'.format(q2_pad, q2_pad.shape))\n",
    "    print('')\n",
    "    print('len_questions_2: {}'.format(len_q2))\n",
    "    print('')\n",
    "    print('lables: {}, shape: {}'.format(t, t.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hz3fuPFWB5bM"
   },
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32610,
     "status": "ok",
     "timestamp": 1616587077106,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "bqz-MTEHB5bM",
    "outputId": "926f9d88-f246-471c-aeb6-2a98a1de0061"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32605,
     "status": "ok",
     "timestamp": 1616587077107,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "kvraNadRB5bM"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "  def __init__(self, n_vocabs, embed_dims, n_lstm_units, n_lstm_layers, n_output_classes):\n",
    "    super(BiLSTM, self).__init__()\n",
    "    self.v = n_vocabs\n",
    "    self.e = embed_dims\n",
    "    self.u = n_lstm_units\n",
    "    self.l = n_lstm_layers\n",
    "    self.o = n_output_classes\n",
    "    self.padd_idx = tokenizer.get_vocab()['[PAD]']\n",
    "    self.embed = nn.Embedding(\n",
    "        self.v,\n",
    "        self.e,\n",
    "        self.padd_idx\n",
    "        )\n",
    "    self.bilstm = nn.LSTM(\n",
    "        self.e,\n",
    "        self.u,\n",
    "        self.l,\n",
    "        batch_first = True,\n",
    "        bidirectional = True,\n",
    "        dropout = 0.5\n",
    "        )\n",
    "    self.linear = nn.Linear(\n",
    "        self.u * 4,\n",
    "        self.o\n",
    "        )  \n",
    "  \n",
    "  def forward(self, X):\n",
    "    # initial_hidden\n",
    "    h0 = torch.zeros(self.l * 2, X[0].size(0), self.u).to(device)\n",
    "    c0 = torch.zeros(self.l * 2, X[0].size(0), self.u).to(device)\n",
    "    \n",
    "    # embedding\n",
    "    out1 = self.embed(X[0].to(device))\n",
    "    out2 = self.embed(X[1].to(device))\n",
    "\n",
    "    # pack_padded_sequence\n",
    "    out1 = nn.utils.rnn.pack_padded_sequence(out1, torch.tensor(X[3]).to(device), batch_first=True, enforce_sorted=False)\n",
    "    out2 = nn.utils.rnn.pack_padded_sequence(out2, torch.tensor(X[4]).to(device), batch_first=True, enforce_sorted=False)\n",
    "    \n",
    "    # NxTxh, lxNxh\n",
    "    out1, _ = self.bilstm(out1, (h0, c0))\n",
    "    out2, _ = self.bilstm(out2, (h0, c0))\n",
    "    \n",
    "    # pad_packed_sequence\n",
    "    out1, _ = nn.utils.rnn.pad_packed_sequence(out1, batch_first=True)\n",
    "    out2, _ = nn.utils.rnn.pad_packed_sequence(out2, batch_first=True)\n",
    "\n",
    "    # take only the final time step\n",
    "    out1 = out1[range(out1.shape[0]), torch.tensor(X[3]).to(device) - 1, :]\n",
    "    out2 = out2[range(out2.shape[0]), torch.tensor(X[4]).to(device) - 1, :]\n",
    "    \n",
    "    # concatenate out1&2\n",
    "    out = torch.cat((out1, out2), 1)\n",
    "    \n",
    "    # linear layer\n",
    "    out = self.linear(out)\n",
    "\n",
    "    iout = torch.max(out, 1)[1]\n",
    "    return iout, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 69602,
     "status": "ok",
     "timestamp": 1616587114106,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "T2j4t2E_cfQQ"
   },
   "outputs": [],
   "source": [
    "train_labels = torch.cat([i[2] for i in train_loader])\n",
    "negative = (train_labels == 0.).sum(dim=0).item()\n",
    "positive = (train_labels == 1.).sum(dim=0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 69597,
     "status": "ok",
     "timestamp": 1616587114107,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "bzNEqS_wr6Vl",
    "outputId": "795a6a29-e5db-4268-a4d5-ce4369d9d04e"
   },
   "outputs": [],
   "source": [
    "print(f'number data in training set {len(train_data)}')\n",
    "print(f'number of negative data in training set {negative}')\n",
    "print(f'number of positive data in training set {positive}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rwc0sJsffEPz"
   },
   "source": [
    "class_weight :\n",
    "\n",
    "n = 203998 * (119431 / (119431 + 203998)) = 75329.3153613312\n",
    "\n",
    "p = 119431 * (203998 / (119431 + 203998)) = 75329.3153613312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 70110,
     "status": "ok",
     "timestamp": 1616587114623,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "66js3dybbCF3"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = BiLSTM(tokenizer.get_vocab_size(), 512, 512, 2, 2).to(device)\n",
    "class_weight = torch.tensor([positive/(positive+negative), negative/(positive+negative)]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight, reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr = 1e-3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 70104,
     "status": "ok",
     "timestamp": 1616587114623,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "G5dVk_Okt7yR",
    "outputId": "598bcc6c-c4a1-4cb3-e8b9-96eb452c7acd"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "executionInfo": {
     "elapsed": 121083,
     "status": "error",
     "timestamp": 1616587165611,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "6i_pGvc-1-4o",
    "outputId": "9681bf47-c8ea-44f5-b42b-cca21ae6be58"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 5\n",
    "losses = []\n",
    "accuracies  = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_loss_min = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    print('epoch: {}/{}:'.format(epoch + 1, num_epochs))   \n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    train_tqdm_bar = tqdm(enumerate(train_loader), total = (len(train_loader)), leave = False, position = 0, file = sys.stdout, dynamic_ncols = True)\n",
    "    val_tqdm_bar = tqdm(enumerate(validation_loader), total = (len(validation_loader)),  leave = False, position = 0, file = sys.stdout, dynamic_ncols = True)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for idx, X in train_tqdm_bar:\n",
    "        labels = X[2].to(device)\n",
    "        iout, out = model(X)\n",
    "        loss = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        running_corrects += torch.sum(iout == labels)\n",
    "        train_tqdm_bar.set_description(desc = 'train'.format(epoch + 1, num_epochs))\n",
    "        batch_idx = (idx + 1) * 64\n",
    "\n",
    "        train_tqdm_bar.set_postfix(\n",
    "            loss = running_loss.item() / batch_idx if idx + 1 < len(train_loader) else running_loss.item() / len(train_loader.dataset)\n",
    "            ,acc = running_corrects.item() / batch_idx if idx + 1 < len(train_loader) else running_corrects.item() / len(train_loader.dataset)\n",
    "            )\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_idx, v_X in val_tqdm_bar:\n",
    "            v_labels = v_X[2].to(device)\n",
    "            v_iout, v_out = model(v_X)\n",
    "            v_loss = criterion(v_out, v_labels)\n",
    "            val_running_loss += v_loss\n",
    "            val_running_corrects += torch.sum(v_iout == v_labels)\n",
    "            val_tqdm_bar.set_description('validate'.format(epoch + 1, num_epochs))\n",
    "            val_batch_idx = (val_idx + 1) * 128\n",
    "\n",
    "            val_tqdm_bar.set_postfix(\n",
    "                val_loss = val_running_loss.item() / val_batch_idx if val_idx + 1 < len(validation_loader) else val_running_loss.item() / len(validation_loader.dataset)\n",
    "                ,val_acc = val_running_corrects.item() / val_batch_idx if val_idx + 1 < len(validation_loader) else val_running_corrects.item() / len(validation_loader.dataset)\n",
    "                )\n",
    "    \n",
    "    epoch_loss = running_loss/len(train_loader.dataset)\n",
    "    losses.append(epoch_loss)\n",
    "    epoch_accuracy = running_corrects/len(train_loader.dataset)\n",
    "    accuracies.append(epoch_accuracy)\n",
    "    val_epoch_loss = val_running_loss/len(validation_loader.dataset)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_epoch_accuracy = val_running_corrects/len(validation_loader.dataset)\n",
    "    val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1\n",
    "            ,'state_dict': model.state_dict()\n",
    "            ,'optimizer' : optimizer.state_dict()\n",
    "            ,'val_loss_min' : val_epoch_loss\n",
    "            }\n",
    "    \n",
    "    print('training loss: {:.4f}, acc: {:.2f}'.format(epoch_loss, epoch_accuracy))\n",
    "    print('validation loss: {:.4f}, acc: {:.2f}'.format(val_epoch_loss, val_epoch_accuracy))\n",
    "    print('elapsed time: {}'.format(str(datetime.now() - t0).split('.')[0]))\n",
    "\n",
    "    if val_epoch_loss <= val_loss_min:\n",
    "      print('validation loss decreased from {:.4f} to {:.4f}, saving model...'.format(val_loss_min, val_epoch_loss))\n",
    "      # torch.save(checkpoint, 'checkpoint/ex2/question_pairs_lowest_val_loss_epoch_{}.pth'.format(epoch + 1))\n",
    "      val_loss_min = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 121076,
     "status": "aborted",
     "timestamp": 1616587165608,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "FGH5nSZCFZPR"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.figure()\n",
    "plt.plot(accuracies, color = 'magenta')\n",
    "plt.plot(val_accuracies, color = '#606060')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.legend(['train_acc', 'val_acc'], loc = 'lower right')\n",
    "plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
    "plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 121076,
     "status": "aborted",
     "timestamp": 1616587165610,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "BLlgEBleGHxw"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, color = 'magenta')\n",
    "plt.plot(val_losses, color = '#606060')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.legend(['train_loss', 'val_loss'], loc = 'upper right')\n",
    "plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
    "plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "bpe_tokenizer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}