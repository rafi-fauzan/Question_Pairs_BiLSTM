{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4240,
     "status": "ok",
     "timestamp": 1616587419410,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "P1sSXAqDlcNA",
    "outputId": "f2262533-9dcd-4662-a948-d5d262c0fe4b"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/MyDrive/Question_Pairs_BiLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JvqIuYD2aZ0"
   },
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6872,
     "status": "ok",
     "timestamp": 1616587423313,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "85rAhA-aBHR8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9426,
     "status": "ok",
     "timestamp": 1616587426137,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "sHn5rDrkAReY"
   },
   "outputs": [],
   "source": [
    "question_1 = torchtext.legacy.data.Field(\n",
    "    sequential = True,\n",
    "    lower = True,\n",
    "    batch_first = True,\n",
    "    tokenize = 'spacy',\n",
    "    pad_first = True,\n",
    "    use_vocab = True\n",
    "    )\n",
    "question_2 = torchtext.legacy.data.Field(\n",
    "    sequential = True,\n",
    "    lower = True,\n",
    "    batch_first = True,\n",
    "    tokenize = 'spacy',\n",
    "    pad_first = True,\n",
    "    use_vocab = True\n",
    "    )\n",
    "target = torchtext.legacy.data.Field(\n",
    "    sequential = False,\n",
    "    use_vocab = False,\n",
    "    is_target = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1uVb45PiARjW"
   },
   "outputs": [],
   "source": [
    "train_data, validation_data = torchtext.legacy.data.TabularDataset.splits(\n",
    "    path = 'data', \n",
    "    train = 'train_dataset.csv',\n",
    "    validation = 'val_dataset.csv',\n",
    "    format = 'csv',\n",
    "    skip_header = True,\n",
    "    fields = [('q1', question_1), ('q2', question_2), ('t', target)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "DOUVW_NwARmU"
   },
   "outputs": [],
   "source": [
    "# build vocab\n",
    "question_1.build_vocab(train_data)\n",
    "question_2.build_vocab(train_data)\n",
    "question_1.vocab.extend(question_2.vocab)\n",
    "question_2.vocab = question_1.vocab\n",
    "vocab = question_1.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "e1crfRIEAulj"
   },
   "outputs": [],
   "source": [
    "train_loader, validation_loader = torchtext.legacy.data.BucketIterator.splits(\n",
    "    (train_data, validation_data), \n",
    "    sort_key = lambda x: len(x.q1)+len(x.q2),\n",
    "    batch_sizes = (64,128),\n",
    "    device = device\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "JpZi5SYBBnul"
   },
   "outputs": [],
   "source": [
    "for q, t in train_loader:\n",
    "    print('questions_1: {}, shape: {}'.format(q[0], q[0].shape))\n",
    "    print('')\n",
    "    print('questions_2: {}, shape: {}'.format(q[1], q[1].shape))\n",
    "    print('')\n",
    "    print('lables: {}, shape: {}'.format(t, t.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "YNGkQZ60BnxK"
   },
   "outputs": [],
   "source": [
    "for q, t in validation_loader:\n",
    "    print('questions_1: {}, shape: {}'.format(q[0], q[0].shape))\n",
    "    print('')\n",
    "    print('questions_2: {}, shape: {}'.format(q[1], q[1].shape))\n",
    "    print('')\n",
    "    print('lables: {}, shape: {}'.format(t, t.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fOW5bPA7CPEv"
   },
   "source": [
    "### Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1225,
     "status": "ok",
     "timestamp": 1616570357816,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "zCxEJKxBBnz6",
    "outputId": "11688015-344b-417c-e3ec-c616479b2108"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KS4jopk-CHDG"
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "  def __init__(self, n_vocabs, embed_dims, n_lstm_units, n_lstm_layers, n_output_classes):\n",
    "    super(BiLSTM, self).__init__()\n",
    "    self.v = n_vocabs\n",
    "    self.e = embed_dims\n",
    "    self.u = n_lstm_units\n",
    "    self.l = n_lstm_layers\n",
    "    self.o = n_output_classes\n",
    "    self.padd_idx = vocab.stoi['<pad>']\n",
    "    self.embed = nn.Embedding(\n",
    "        self.v,\n",
    "        self.e,\n",
    "        self.padd_idx\n",
    "        )\n",
    "    self.bilstm = nn.LSTM(\n",
    "        self.e,\n",
    "        self.u,\n",
    "        self.l,\n",
    "        batch_first = True,\n",
    "        bidirectional = True,\n",
    "        dropout = 0.5\n",
    "        )\n",
    "    self.linear = nn.Linear(\n",
    "        self.u * 4,\n",
    "        self.o\n",
    "        )  \n",
    "  \n",
    "  def forward(self, X1, X2):\n",
    "    # initial_hidden\n",
    "    h0 = torch.zeros(self.l * 2, X1.size(0), self.u).to(device)\n",
    "    c0 = torch.zeros(self.l * 2, X1.size(0), self.u).to(device)\n",
    "    \n",
    "    # embedding\n",
    "    out1 = self.embed(X1.to(device))\n",
    "    out2 = self.embed(X2.to(device))\n",
    "\n",
    "    # pack_padded_sequence\n",
    "    # out1 = nn.utils.rnn.pack_padded_sequence(out1, ??, batch_first=True, enforce_sorted=False)\n",
    "    # out2 = nn.utils.rnn.pack_padded_sequence(out2, ??, batch_first=True, enforce_sorted=False)\n",
    "    \n",
    "    # NxTxh, lxNxh\n",
    "    out1, _ = self.bilstm(out1, (h0, c0))\n",
    "    out2, _ = self.bilstm(out2, (h0, c0))\n",
    "    \n",
    "    # pad_packed_sequence\n",
    "    # out1, _ = nn.utils.rnn.pad_packed_sequence(out1, batch_first=True)\n",
    "    # out2, _ = nn.utils.rnn.pad_packed_sequence(out2, batch_first=True)\n",
    "\n",
    "    # take only the final time step\n",
    "    out1 = out1[:, -1, :]\n",
    "    out2 = out2[:, -1, :]\n",
    "    \n",
    "    # concatenate out1&2\n",
    "    out = torch.cat((out1, out2), 1)\n",
    "    \n",
    "    # linear layer\n",
    "    out = self.linear(out)\n",
    "\n",
    "    iout = torch.max(out, 1)[1]\n",
    "    return iout, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4hvGH2cAARru"
   },
   "outputs": [],
   "source": [
    "train_labels = torch.cat([t for q1, t in train_loader])\n",
    "negative = (train_labels == 0.).sum(dim=0).item()\n",
    "positive = (train_labels == 1.).sum(dim=0).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1272,
     "status": "ok",
     "timestamp": 1616570374620,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "ZUv6YkdeDgjL",
    "outputId": "f8022d5e-7036-4631-e4c9-d553cee135b4"
   },
   "outputs": [],
   "source": [
    "print(f'number data in training set {len(train_data)}')\n",
    "print(f'number of negative data in training set {negative}')\n",
    "print(f'number of positive data in training set {positive}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "muePOwNJEKDO"
   },
   "source": [
    "class_weight :\n",
    "\n",
    "n = 203998 * (119431 / (119431 + 203998)) = 75329.3153613312\n",
    "\n",
    "p = 119431 * (203998 / (119431 + 203998)) = 75329.3153613312"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Dpsz1QcDgmD"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = BiLSTM(len(vocab), 512, 512, 2, 2).to(device)\n",
    "class_weight = torch.tensor([positive/(positive+negative), negative/(positive+negative)]).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weight, reduction='mean').to(device)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), \n",
    "    lr = 1e-3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1393,
     "status": "ok",
     "timestamp": 1616570537445,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "q7wimry6EFBU",
    "outputId": "a4ef73b4-cf0b-4f36-ad34-71c30a11764e"
   },
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 37667,
     "status": "error",
     "timestamp": 1616570575695,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "WREmz6bGEFDX",
    "outputId": "00aead6f-8697-4e62-f3b9-c556fc90b15e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 5\n",
    "losses = []\n",
    "accuracies  = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "val_loss_min = np.inf\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    print('epoch: {}/{}:'.format(epoch + 1, num_epochs))   \n",
    "    print('------------------------------------------------------------------------------------------')\n",
    "    t0 = datetime.now()\n",
    "\n",
    "    train_tqdm_bar = tqdm(enumerate(train_loader), total = (len(train_loader)), leave = False, position = 0, file = sys.stdout, dynamic_ncols = True)\n",
    "    val_tqdm_bar = tqdm(enumerate(validation_loader), total = (len(validation_loader)),  leave = False, position = 0, file = sys.stdout, dynamic_ncols = True)\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "\n",
    "    model.train()\n",
    "    for idx, (docs, labels) in train_tqdm_bar:\n",
    "        iout, out = model(docs[0], docs[1])\n",
    "        loss = criterion(out, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = 1)\n",
    "        optimizer.step()\n",
    "        running_loss += loss\n",
    "        running_corrects += torch.sum(iout == labels)\n",
    "        train_tqdm_bar.set_description(desc = 'train'.format(epoch + 1, num_epochs))\n",
    "        batch_idx = (idx + 1) * 64\n",
    "\n",
    "        train_tqdm_bar.set_postfix(\n",
    "            loss = running_loss.item() / batch_idx if idx + 1 < len(train_loader) else running_loss.item() / len(train_loader.dataset)\n",
    "            ,acc = running_corrects.item() / batch_idx if idx + 1 < len(train_loader) else running_corrects.item() / len(train_loader.dataset)\n",
    "            )\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for val_idx, (v_docs, v_labels) in val_tqdm_bar:\n",
    "            v_iout, v_out = model(v_docs[0], v_docs[1])\n",
    "            v_loss = criterion(v_out, v_labels)\n",
    "            val_running_loss += v_loss\n",
    "            val_running_corrects += torch.sum(v_iout == v_labels)\n",
    "            val_tqdm_bar.set_description('validate'.format(epoch + 1, num_epochs))\n",
    "            val_batch_idx = (val_idx + 1) * 128\n",
    "\n",
    "            val_tqdm_bar.set_postfix(\n",
    "                val_loss = val_running_loss.item() / val_batch_idx if val_idx + 1 < len(validation_loader) else val_running_loss.item() / len(validation_loader.dataset)\n",
    "                ,val_acc = val_running_corrects.item() / val_batch_idx if val_idx + 1 < len(validation_loader) else val_running_corrects.item() / len(validation_loader.dataset)\n",
    "                )\n",
    "    \n",
    "    epoch_loss = running_loss/len(train_loader.dataset)\n",
    "    losses.append(epoch_loss)\n",
    "    epoch_accuracy = running_corrects/len(train_loader.dataset)\n",
    "    accuracies.append(epoch_accuracy)\n",
    "    val_epoch_loss = val_running_loss/len(validation_loader.dataset)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "    val_epoch_accuracy = val_running_corrects/len(validation_loader.dataset)\n",
    "    val_accuracies.append(val_epoch_accuracy)\n",
    "\n",
    "    checkpoint = {\n",
    "            'epoch': epoch + 1\n",
    "            ,'state_dict': model.state_dict()\n",
    "            ,'optimizer' : optimizer.state_dict()\n",
    "            ,'val_loss_min' : val_epoch_loss\n",
    "            }\n",
    "    \n",
    "    print('training loss: {:.4f}, acc: {:.2f}'.format(epoch_loss, epoch_accuracy))\n",
    "    print('validation loss: {:.4f}, acc: {:.2f}'.format(val_epoch_loss, val_epoch_accuracy))\n",
    "    print('elapsed time: {}'.format(str(datetime.now() - t0).split('.')[0]))\n",
    "\n",
    "    if val_epoch_loss <= val_loss_min:\n",
    "      print('validation loss decreased from {:.4f} to {:.4f}, saving model...'.format(val_loss_min, val_epoch_loss))\n",
    "      # torch.save(checkpoint, 'checkpoint/question_pairs_lowest_val_loss_epoch_{}.pth'.format(epoch + 1))\n",
    "      val_loss_min = val_epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "executionInfo": {
     "elapsed": 1142,
     "status": "ok",
     "timestamp": 1616570660713,
     "user": {
      "displayName": "testaja test",
      "photoUrl": "",
      "userId": "08960270030243762476"
     },
     "user_tz": -420
    },
    "id": "NN3GTUXyEVI_",
    "outputId": "b23742b6-1ea7-4072-a9a5-edf8ed0a5edd"
   },
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-darkgrid')\n",
    "plt.figure()\n",
    "plt.plot(accuracies, color = 'magenta')\n",
    "plt.plot(val_accuracies, color = '#606060')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.legend(['train_acc', 'val_acc'], loc = 'lower right')\n",
    "plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
    "plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0Lf1bgJEFFX"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(losses, color = 'magenta')\n",
    "plt.plot(val_losses, color = '#606060')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch #')\n",
    "plt.legend(['train_loss', 'val_loss'], loc = 'upper right')\n",
    "plt.grid(axis = 'y', c = 'black', alpha = 0.2)\n",
    "plt.grid(axis = 'x', c = 'black', alpha = 0.2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "question_pairs_bilstm.ipynb",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
